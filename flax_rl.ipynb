{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def init_board():\n",
    "  return jnp.zeros((4, 4), dtype=int)\n",
    "\n",
    "def flip_board(board):\n",
    "  return -board\n",
    "\n",
    "def valid_mask(board):\n",
    "  return board == 0\n",
    "\n",
    "#Always assume action is made by player 1\n",
    "def next_state(board, action):\n",
    "  return board.flatten().at[action].add(1).reshape(board.shape)\n",
    "\n",
    "def sample_action(action_dist, rng):\n",
    "  action_dist = action_dist.flatten() / action_dist.sum()\n",
    "  return jax.random.choice(rng, jnp.arange(action_dist.shape[0]), p=action_dist)\n",
    "\n",
    "def disp_board(board):\n",
    "  plt.imshow(board)\n",
    "\n",
    "reward_conv = nn.Conv(features=4, kernel_size=(3, 3), use_bias=False, padding='SAME')\n",
    "stripe_filter = jnp.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
    "reward_kernel = jnp.expand_dims(jnp.stack([jnp.eye(3), jnp.eye(3)[::-1, :], stripe_filter, stripe_filter.T], axis=2), 2)\n",
    "\n",
    "conv_param = {'params': {'kernel': reward_kernel}}\n",
    "# print(jnp.expand_dims(jnp.eye(4), (0, 3)))\n",
    "\n",
    "def get_reward(board, conv_param):\n",
    "    board_score = reward_conv.apply(conv_param, jnp.expand_dims(board, (0, 3)))\n",
    "    # print(jnp.transpose(board_score[0]))\n",
    "    is_win = (jnp.max(board_score) >= 3).astype(int)\n",
    "    is_loss = (jnp.min(board_score) <= -3).astype(int)\n",
    "    return is_win - is_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "board = init_board()\n",
    "\n",
    "rng = jax.random.PRNGKey(40)\n",
    "for i in range(16):\n",
    "  _, rng = jax.random.split(rng, 2)\n",
    "  action_dist = jnp.ones(board.shape) * valid_mask(board)\n",
    "  next_action = sample_action(action_dist, rng)\n",
    "  board = flip_board(next_state(board, next_action))\n",
    "  reward = get_reward(board, conv_param)\n",
    "  print(reward)\n",
    "  if(reward != 0):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-1, dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# board = board.at[3, 0].set(0)\n",
    "# print(board)\n",
    "\n",
    "get_reward(-jnp.eye(4, dtype=int), conv_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax import traverse_util\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # Optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "  def __init__(self, prior):\n",
    "      self.prior = prior      # The prior probability of selecting this state from its parent\n",
    "\n",
    "      self.children = {}      # A lookup of legal child positions\n",
    "      self.visit_count = 0    # Number of times this state was visited during MCTS. \"Good\" are visited more then \"bad\" states.\n",
    "      self.value_sum = 0      # The total value of this state from all visits\n",
    "      self.state = None       # The board state as this node\n",
    "\n",
    "  def value(self):\n",
    "       # Average value for a node\n",
    "      return self.value_sum / self.visit_count\n",
    "\n",
    "def run(self, state, num_simulations=5):\n",
    "    root = Node(0)\n",
    "    # EXPAND root\n",
    "    root.expand(self.model, self.game, state)\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        search_path = [node]\n",
    "        # SELECT\n",
    "        while node.expanded():\n",
    "            action, node = node.select_child()\n",
    "            search_path.append(node)\n",
    "\n",
    "        parent = search_path[-2]                                                  \n",
    "        state = parent.state                                                      \n",
    "        next_state, _ = self.game.get_next_state(state, action=action) \n",
    "        value = self.game.get_reward_for_player(next_state, player=1)\n",
    "        if value is None:\n",
    "            # EXPAND\n",
    "            value = node.expand(self.model, self.game, flip_board(next_state))\n",
    "\n",
    "        self.backup(search_path, value, parent.to_play * -1)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STATE_DIM = 16 #Dimension of 4x4 tic-tac-toe board\n",
    "ACTION_DIM = 16\n",
    "MAX_SIZE = 1e6\n",
    "C_BASE, C_INIT = 1.0, 1.0\n",
    "class MCTS:\n",
    "    def __init__(self):\n",
    "        self.state = np.zeros((STATE_DIM, MAX_SIZE))\n",
    "        self.state_lookup = {} #Maps state representation to index\n",
    "\n",
    "        self.value = np.zeros(MAX_SIZE)\n",
    "        self.visit_count = np.zeros(MAX_SIZE)\n",
    "        self.total_value = np.zeros(MAX_SIZE)\n",
    "        \n",
    "        self.action_visits  = np.zeros(MAX_SIZE, ACTION_DIM)\n",
    "        self.action_total_value = np.zeros(MAX_SIZE, ACTION_DIM)\n",
    "        self.action_mean_value = np.zeros(MAX_SIZE, ACTION_DIM)\n",
    "        self.action_prior = np.zeros(MAX_SIZE, ACTION_DIM)\n",
    "    \n",
    "    #Assumes state is already expanded, and uses MCTS info to pick best action\n",
    "    def select_action(self, state_index):\n",
    "        state_visits = self.visit_count[state_index]\n",
    "        exp_rate = np.log((1+state_visits + C_BASE)/C_BASE) + C_INIT\n",
    "        model_prior = self.action_prior[state_index]\n",
    "        sa_visits = self.action_visits[state_index]\n",
    "        sa_mean_value = self.action_mean_value[state_index]\n",
    "        action_distr = sa_mean_value + exp_rate*np.sqrt(state_visits)*model_prior/(1+sa_visits)\n",
    "        return np.argmax(action_distr)\n",
    "\n",
    "    def search(self, state, model):\n",
    "    \n",
    "    def search_batch(self, state, model):\n",
    "\n",
    "    def est_action_distr(self, state, model):\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, inp_rng, init_rng = jax.random.split(rng, 3)\n",
    "inp = jnp.zeros((10, 10, 1))\n",
    "\n",
    "# params = conv.init(init_rng, inp)\n",
    "# print(jax.tree_util.tree_map(jnp.shape, params))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    return x\n",
    "\n",
    "cnn = CNN()\n",
    "params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1c2c9eb50c248e284b0bf4da0c34373df9866a584f49a897fbedf2615d148e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 ('azur_rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
